{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.linear_model import Ridge, BayesianRidge, ElasticNet, RidgeCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(file_name, file_name_D):\n",
    "    \"\"\"\n",
    "    Read the csv files and create game characterstic features and player statistic features\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_name)\n",
    "    df_D = pd.read_csv(file_name_D)\n",
    "    df.sort_values(by = ['Name', 'Unnamed: 2_level_0 G#']) # for rolling average\n",
    "    # All box score player stats, except defensive statistics\n",
    "    stats = ['Passing AY/A', 'Passing Att', 'Passing Cmp', 'Passing Cmp%',\n",
    "            'Passing Int', 'Passing Rate', 'Passing Sk', 'Passing TD',\n",
    "            'Passing Y/A', 'Passing Yds', 'Passing Yds.1', 'Rushing Att',\n",
    "            'Rushing TD', 'Rushing Y/A', 'Rushing Yds','FPoints']\n",
    "    # Opponent Characteristics\n",
    "    df, opp_features = get_opp_d(df, df_D)\n",
    "    # Game Characteristic Indicators, e.g. home/away, opponent, team\n",
    "#     df, game_features = get_game_char_indicators(df)\n",
    "    # Player Statistic Features, e.g. Season, last 4 weeks, previous week\n",
    "    df, player_features = get_player_averages(df, stats)\n",
    "#     features = game_features + player_features\n",
    "#     features = player_features\n",
    "    features = player_features + opp_features\n",
    "    df = df.fillna(0)\n",
    "    return df, features\n",
    "\n",
    "\n",
    "def get_game_char_indicators(df):\n",
    "    \"\"\"\n",
    "    Transform str cols into game categorical variables\n",
    "    Returns transformed and columns\n",
    "    \"\"\"\n",
    "    df['home'] = 1 * df['Unnamed: 6_level_0 Unnamed: 6_level_1'] == '0'\n",
    "    oppts = pd.get_dummies(df['Unnamed: 7_level_0 Opp'], prefix='Oppt')\n",
    "    teams = pd.DataFrame()\n",
    "    team_list = pd.Series('ARI', 'ATL', 'BAL', 'BUF', 'CAR', 'CHI', 'CIN', 'CLE', 'DAL', 'DEN', 'DET',\\\n",
    "                           'GB', 'HOU', 'IND', 'JAC', 'KC', 'MIA', 'MIN', 'NE', 'NO', 'NYG', 'NYJ',\\\n",
    "                           'OAK', 'PHI', 'PIT', 'SD', 'SEA', 'SF', 'STL', 'TB', 'TEN', 'WAS')\n",
    "    for team in df['Unnamed: 5_level_0 Tm']:\n",
    "        temp = (team_list == team)\n",
    "        teams = teams.append(temp, ignore_index=True)\n",
    "    teams.index = range(len(df['Unnamed: 5_level_0 Tm']))\n",
    "    teams.columns = list(team_list)\n",
    "    df = pd.concat([df, oppts, teams], axis=1)\n",
    "    return df, ['home'] + list(oppts.columns) + list(team_list)\n",
    "\n",
    "def get_opp_d(df, df_D):\n",
    "\n",
    "    d_stats = ['PF', 'Yds','Tot Yds & TO Ply','Tot Yds & TO Y/P','Tot Yds & TO TO','FL','1stD','Passing Cmp','Passing Att',\n",
    "             'Passing Yds','Passing TD','Passing Int','Passing NY/A','Passing 1stD','Penalties Pen','Penalties Yds',\n",
    "             'Penalties 1stPy','Sc%','Unnamed: 26_level_0 TO%','EXP']\n",
    "    df_D['Season']= df_D['Season'].astype(str)\n",
    "#     for stat in df[d_stats + ['FPoints']]:\n",
    "#         opp = abbrev_dict[df['Unnamed: 7_level_0 Opp']]\n",
    "#         df['D_'+stat] = df_D.loc[df_D['Tm'] == opp][stat]\n",
    "    for stat in d_stats:\n",
    "#         print(stat)\n",
    "        df[stat] = df.apply(lambda row: get_team_stat(row,stat,df_D), axis=1)\n",
    "    return df, d_stats\n",
    "def get_team_stat(row,stat,df_D):\n",
    "    abbrev_dict = {'ARI':'Arizona Cardinals', 'ATL':'Atlanta Falcons', 'BAL':'Baltimore Ravens', 'BUF':'Buffalo Bills', \n",
    "                          'CAR':'Carolina Panthers', 'CHI':'Chicago Bears', 'CIN':'Cincinnati Bengals', \n",
    "                          'CLE':'Cleveland Browns', 'DAL':'Dallas Cowboys', 'DEN':'Denver Broncos', 'DET':'Detroit Lions', \n",
    "                          'GB':'Green Bay Packers','GNB':'Green Bay Packers', 'HOU': 'Houston Texans', 'IND':'Indianapolis Colts', \n",
    "                          'JAC':'Jacksonville Jaguars', 'JAX':'Jacksonville Jaguars','KAN':'Kansas City Chiefs','KC':'Kansas City Chiefs','LAC':'Los Angeles Chargers',\n",
    "                          'LAR':'Los Angeles Rams', 'MIA':'Miami Dolphins', 'MIN':'Minnesota Vikings','NE':'New England Patriots','NWE':'New England Patriots',\n",
    "                          'NO':'New Orleans Saints','NOR':'New Orleans Saints', 'NYG':'New York Giants', 'NYJ':'New York Jets','OAK':'Oakland Raiders', \n",
    "                          'PHI':'Philadelphia Eagles', 'PIT':'Pittsburgh Steelers', 'SD':'San Diego Chargers', 'SDG':'San Diego Chargers', 'SEA':'Seattle Seahawks', \n",
    "                          'SF':'San Francisco 49ers', 'SFO':'San Francisco 49ers','STL':'St. Louis Rams', 'TB':'Tampa Bay Buccaneers',\n",
    "                           'TEN':'Tennessee Titans', 'TAM':'Tampa Bay Buccaneers',\n",
    "                          'WAS':'Washington Redskins'}\n",
    "#     print(row)\n",
    "#     print(df_D['Season'])\n",
    "    df_D.index=df_D['Tm']+df_D['Season']\n",
    "#     print(df_D)\n",
    "    opp = abbrev_dict[row['Unnamed: 7_level_0 Opp']]+str(row['Season'])\n",
    "#     print(type(df_D.loc[df_D['Tm']==opp][stat]))\n",
    "#     print(opp,stat)\n",
    "    return df_D.at[opp,stat]\n",
    "\n",
    "def rolling_average(df, window):\n",
    "    return df.rolling(min_periods=1, window=window).mean().shift(1)\n",
    "\n",
    "def get_player_averages(df, stats):\n",
    "    \"\"\"\n",
    "    Estimate player averages for all stats and FanDuel point histories,\n",
    "    for season-to-date, last 4 weeeks, and previous week\n",
    "    \"\"\"\n",
    "    feature_names = []\n",
    "    for stat in df[stats + ['FPoints']]:\n",
    "        df['season_{}'.format(stat)] = df.groupby('Name')[stat].apply(lambda x: rolling_average(x, 16))\n",
    "        df['recent_{}'.format(stat)] = df.groupby('Name')[stat].apply(lambda x: rolling_average(x, 4))\n",
    "        df['prev_{}'.format(stat)] = df.groupby('Name')[stat].apply(lambda x: rolling_average(x, 1))\n",
    "        feature_names = feature_names + [time + \"_\" + stat for time in ['season', 'recent', 'prev']]\n",
    "    return df, feature_names\n",
    "\n",
    "\n",
    "path = \"data/\"\n",
    "train, features = data_processing(path + 'QB_all.csv', path + 'teams_all.csv')\n",
    "# test, features2 = data_processing(path + 'gamelog_QB_2018.csv', path + 'teams_2018.csv')\n",
    "# if (features != features2):\n",
    "#     print(\"Debug error about feature inconsistency\")\n",
    "#     exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, features2 = data_processing(path + 'gamelog_QB_2018.csv', path + 'teams_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = sorted(train['Position'].unique())\n",
    "estimators = [\"Ridge\",\n",
    "              \"ElasticNet\",\n",
    "              \"RandomForestRegressor\"\n",
    "              # \"GradientBoostingRegressor\"\n",
    "              # \"SVM\"\n",
    "              ]\n",
    "types = ['train', 'cv', 'test']\n",
    "# Dataframe index, e.g. Ridge_train\n",
    "rmse_names = [x + '_' + y for y in types for x in estimators]\n",
    "df_rmse = pd.DataFrame([[0.0] for j in range(len(rmse_names))], \n",
    "    index = rmse_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning for Position QB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raymond\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Raymond\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Raymond\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Raymond\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Raymond\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Raymond\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for position in positions:\n",
    "    # Iterate through all positions\n",
    "    print ('Learning for Position %s ...' % position)\n",
    "    df_pos_train = train.loc[train['Position'] == position,]\n",
    "    df_pos_test = test.loc[test['Position'] == position,]\n",
    "\n",
    "    for i in range(len(estimators)):\n",
    "        est = estimators[i]\n",
    "\n",
    "        if(est == \"GradientBoostingRegressor\"):\n",
    "            n_estimators = [50]\n",
    "            learning_rate = [0.1]\n",
    "            param_grid = {'n_estimators': n_estimators, 'learning_rate': learning_rate}\n",
    "            grid_search = GridSearchCV(GradientBoostingRegressor(max_depth=3), param_grid, cv=5)\n",
    "            grid_search.fit(df_pos_train[features], df_pos_train['FPoints'])\n",
    "\n",
    "        elif(est == \"RandomForestRegressor\"):\n",
    "            n_estimators = [50]\n",
    "            param_grid = {'n_estimators': n_estimators}\n",
    "            grid_search = GridSearchCV(RandomForestRegressor(max_depth=3), param_grid, cv=5)\n",
    "            grid_search.fit(df_pos_train[features], df_pos_train['FPoints'])\n",
    "\n",
    "        elif(est == \"ElasticNet\"):\n",
    "            grid_search = ElasticNetCV().fit(df_pos_train[features], df_pos_train['FPoints'])\n",
    "\n",
    "        elif(est == \"BayesianRidge\"):\n",
    "            alpha_1 = [1e-6, 1e-5, 1e-7]\n",
    "            alpha_2 = [1e-6, 1e-5, 1e-7]\n",
    "            lambda_1 = [1e-6, 1e-5, 1e-7]\n",
    "            lambda_2 = [1e-6, 1e-5, 1e-7]\n",
    "            param_grid = {'alpha_1': alpha_1, 'alpha_2':alpha_2, 'lambda_1':lambda_1, 'lambda_2':lambda_2}\n",
    "            grid_search = GridSearchCV(BayesianRidge(), param_grid, cv=5)\n",
    "            grid_search.fit(df_pos_train[features], df_pos_train[target])\n",
    "\n",
    "        elif(est == \"Ridge\"):\n",
    "            grid_search = RidgeCV().fit(df_pos_train[features], df_pos_train['FPoints'])\n",
    "\n",
    "        elif(est == \"SVM\"):\n",
    "            C = [50]\n",
    "            gamma = [0.3]\n",
    "            param_grid = {'C': C, 'gamma': gamma}\n",
    "            grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "            grid_search.fit(df_pos_train[features], df_pos_train['FPoints'])\n",
    "\n",
    "        else:\n",
    "            print(est)\n",
    "            print(\"Cannot find the algorithm\")\n",
    "            exit()\n",
    "\n",
    "        train_rmse = np.sqrt(np.mean( (df_pos_train['FPoints'] - \\\n",
    "                    grid_search.predict(df_pos_train[features]))**2.0 ))\n",
    "        test_rmse = np.sqrt(np.mean( (df_pos_test['FPoints'] - \\\n",
    "                    grid_search.predict(df_pos_test[features]))**2.0 ))\n",
    "        # Deprecating \"mean_squared_error\". Use \"neg_mean_squared_error\" instead.\n",
    "        cv_rmse = np.sqrt(np.abs( cross_val_score(grid_search, train[features], train['FPoints'],\\\n",
    "            cv = 5, scoring = 'neg_mean_squared_error').mean() ))\n",
    "\n",
    "        # Given the variable name in a string, get the variable value and import into dataframe\n",
    "        for val in types:\n",
    "            df_rmse.loc[estimators[i] + \"_\" + val, position] = eval(val + '_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'proj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'proj'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c9b794808294>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \"\"\"\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diff'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'proj'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FPoints'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mFantasyData_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Position'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'diff'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mFantasyData_rmse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FantasyData_rmse.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'proj'"
     ]
    }
   ],
   "source": [
    "\"\"\" save rmse into csv \"\"\"\n",
    "\n",
    "df_rmse.to_csv('rmse.csv', header = True, index=True)\n",
    "\n",
    "\"\"\"\n",
    "MSE of FD_2016_Projections.csv (Fantasydata.com)\n",
    "\"\"\"\n",
    "\n",
    "test['diff'] = (test['proj'] - test['FPoints']) ** 2.0\n",
    "FantasyData_rmse = (test.groupby(['Position'])['diff'].mean()) ** 0.5\n",
    "FantasyData_rmse.to_csv('FantasyData_rmse.csv', header = True, index = True)\n",
    "\n",
    "print(\"Program finished normally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
